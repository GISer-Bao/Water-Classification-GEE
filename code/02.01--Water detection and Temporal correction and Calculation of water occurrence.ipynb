{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE : Considering some of GEE's user limits and avoiding some system errors, such as \"ERROR: user memory limit exceeded\",\"TimeoutError\", etc,we will process or download some data beforehand and upload it to GEE Assets, where it will be called up when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T11:42:11.322436Z",
     "start_time": "2022-04-02T11:42:11.316421Z"
    }
   },
   "source": [
    "Special reminder: the following variables or parameters need to be modified\n",
    "\n",
    "Must be amended : \"roi\", \"region\", \"elevation\", \"dataset_id\", \"assetID\", \"filtered_samples\"\n",
    "\n",
    "May have to be modified (Depending on your actual situation) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T12:47:15.233108Z",
     "start_time": "2022-03-07T12:47:15.223135Z"
    }
   },
   "outputs": [],
   "source": [
    "#### If you are trying to use geemap in coutries where Gooogle Services are blocked (e.g., China), \n",
    "#### you will need a VPN,then replace \"10809\" with your \"proxy port number\"to connect to Earth Engine servers.\n",
    "#### Otherwise, you might encounter a connection timeout issue.\n",
    "\n",
    "import os\n",
    "os.environ['HTTP_PROXY'] = \"http://127.0.0.1:10809\"\n",
    "os.environ['HTTPS_PROXY'] = \"http://127.0.0.1:10809\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T12:47:23.119099Z",
     "start_time": "2022-03-07T12:47:16.575573Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Initializing GEE\n",
    "\n",
    "import geemap\n",
    "import ee\n",
    "Map=geemap.Map()\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T12:47:43.184262Z",
     "start_time": "2022-03-07T12:47:41.990406Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Setting the boundaries of the study area.\n",
    "#### Format: ee.Geometry.Rectangle(minLng, minLat, maxLng, maxLat)\n",
    "\n",
    "roi = ee.Geometry.Rectangle([113.7393, 29.8642,115.0993, 30.9242])\n",
    "Map.addLayer(roi, {}, \"roi\")\n",
    "Map.centerObject(roi,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T12:47:43.295013Z",
     "start_time": "2022-03-07T12:47:43.280680Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Defining variables\n",
    "region = 'wuhan'\n",
    "\n",
    "#### Calls for elevation data, which he has downloaded to GEE's Assets in \"00--preparation.ipynb\"\n",
    "elevation = ee.Image(\"users/311605001111/hillshade_wuhan\")\n",
    "\n",
    "#### Visualisation parameters for Landsat8 images\n",
    "visParams = {'bands': ['B5', 'B6', 'B4'],'min': 0,'max': 3000,'gamma': 1.4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T12:47:43.420740Z",
     "start_time": "2022-03-07T12:47:43.392009Z"
    }
   },
   "outputs": [],
   "source": [
    "def water_index(img):\n",
    "    image = img.clip(roi)\n",
    "    ndvi=image.normalizedDifference(['B5', 'B4']).rename('NDVI')\n",
    "    ndwi=image.normalizedDifference(['B3', 'B5']).rename(\"NDWI\")\n",
    "    mndwi=image.normalizedDifference(['B3', 'B6']).rename(\"mNDWI\")\n",
    "    cwi=image.select('B3').divide(image.select('B6')).rename(\"CWI\")\n",
    "    awei = image.expression('(B2 + 2.5*B3 - 1.5*(B5+B6) - 0.25*B7)/10000',\n",
    "        {\n",
    "          'B2': image.select('B2'),\n",
    "          'B3': image.select('B3'),    \n",
    "          'B5': image.select('B5'),    \n",
    "          'B6': image.select('B6'),\n",
    "          'B7': image.select('B7'),\n",
    "        }).rename('AWEI')\n",
    "    ewi = image.expression('(B3 - B5 - B6)/(B3 + B5 + B6)',\n",
    "        {\n",
    "          'B3': image.select('B3'),    \n",
    "          'B5': image.select('B5'),    \n",
    "          'B6': image.select('B6'),\n",
    "        }).rename('EWI')\n",
    "    evi = image.expression('2.5*(B5 - B4)/(B5 + 6*B4 - 7.5*B2 + 1)',\n",
    "        {\n",
    "          'B2': image.select('B2'),\n",
    "          'B4': image.select('B4'),\n",
    "          'B5': image.select('B5'),    \n",
    "        }).rename('EVI')\n",
    "    return image.addBands(ndvi).addBands(ndwi).addBands(mndwi).addBands(cwi).addBands(awei).addBands(ewi).addBands(evi)\n",
    "\n",
    "def maskSR(img):\n",
    "    cloudShadowBitMask = (1 << 3)\n",
    "    cloudsBitMask = (1 << 5)\n",
    "    snowBitMask = (1 << 4)   \n",
    "    qa = img.select('pixel_qa')\n",
    "    mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0) \\\n",
    "                   .And(qa.bitwiseAnd(cloudsBitMask).eq(0)) \\\n",
    "                   .And(qa.bitwiseAnd(snowBitMask).eq(0))\n",
    "    azimuth = img.get('SOLAR_AZIMUTH_ANGLE')\n",
    "    zenith = img.get('SOLAR_ZENITH_ANGLE')\n",
    "    image = img.lt(0)\n",
    "    bands = image.select('B2').add(image.select('B3')).add(image.select('B4')).add(image.select('B5')).add(image.select('B6')).add(image.select('B7'))\n",
    "    outlier = bands.gt(0).remap([0,1],[1,0]).rename('outlier')\n",
    "    return img.updateMask(mask).updateMask(ee.Terrain.hillShadow(elevation,azimuth,zenith,200,True)).updateMask(outlier)\n",
    "\n",
    "def maskSR_reverse(img):\n",
    "    cloudShadowBitMask = (1 << 3)\n",
    "    cloudsBitMask = (1 << 5)\n",
    "    snowBitMask = (1 << 4)   \n",
    "    qa = img.select('pixel_qa')\n",
    "    mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0) \\\n",
    "                   .And(qa.bitwiseAnd(cloudsBitMask).eq(0)) \\\n",
    "                   .And(qa.bitwiseAnd(snowBitMask).eq(0))\n",
    "    image_cloud = img.updateMask(mask.remap([0,1],[1,0]))\n",
    "    azimuth = img.get('SOLAR_AZIMUTH_ANGLE')\n",
    "    zenith = img.get('SOLAR_ZENITH_ANGLE')\n",
    "    image_shadow = img.updateMask(ee.Terrain.hillShadow(elevation,azimuth,zenith,200,True).remap([0,1],[1,0]))\n",
    "    image = img.lt(0)\n",
    "    bands = image.select('B2').add(image.select('B3')).add(image.select('B4')).add(image.select('B5')).add(image.select('B6')).add(image.select('B7'))\n",
    "    image_outlier = img.updateMask(bands.gt(0).rename('outlier'))\n",
    "    return ee.ImageCollection([image_cloud,image_shadow,image_outlier]).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T12:47:44.537335Z",
     "start_time": "2022-03-07T12:47:44.519412Z"
    }
   },
   "outputs": [],
   "source": [
    "## img refers to an image that has been indexed but not cloud-masked\n",
    "def classified_image(img):\n",
    "    image = maskSR(img).select(bands).classify(trainedClassifier).eq(1).remap([0,1],[1,2]).rename('waterclass').float()\n",
    "    invalidPixel = maskSR_reverse(img).select('pixel_qa').gt(0).remap([0,1],[1,0]).rename('waterclass').float()\n",
    "    class_image = ee.ImageCollection([invalidPixel,image]).sum()\n",
    "    invalidPixels = class_image.eq(0).multiply(ee.Image.pixelArea()).divide(1e6)\n",
    "    invalidarea = invalidPixels.reduceRegion(**{'reducer': ee.Reducer.sum(),'geometry': roi,'scale': 500,'maxPixels': 1e14,'tileScale': 2}).get('waterclass')\n",
    "    region = class_image.gte(0).multiply(ee.Image.pixelArea()).divide(1e6)\n",
    "    regionarea = region.reduceRegion(**{'reducer': ee.Reducer.sum(),'geometry': roi,'scale': 500,'maxPixels': 1e14,'tileScale': 2}).get('waterclass')\n",
    "    rate = ee.Number(invalidarea).divide(ee.Number(regionarea)).multiply(100)\n",
    "    return class_image.set({'system:id':img.get('system:id')}).set({'CLOUD_COVER':img.get('CLOUD_COVER')}).set({'invalid_percentage':rate})\n",
    "\n",
    "def waterArea(image):\n",
    "    classified_image = image.select('waterclass').eq(2).rename('waterclass')\n",
    "    water_area = classified_image.multiply(ee.Image.pixelArea()).divide(1e6)\n",
    "    waterarea = water_area.reduceRegion(**{\n",
    "        'reducer': ee.Reducer.sum(),\n",
    "        'geometry': roi,\n",
    "        'scale': 200,\n",
    "        'maxPixels': 1e14,\n",
    "        'tileScale': 2,\n",
    "    })\n",
    "    return image.set({'waterarea': waterarea.get('waterclass')})\n",
    "\n",
    "def occurrence_Histogram(class_image):\n",
    "    water = class_image.eq(2).selfMask()\n",
    "    no_data = class_image.eq(0).selfMask()\n",
    "    occurrence = ee.Image('JRC/GSW1_3/GlobalSurfaceWater').select('occurrence')\n",
    "    occurrence_water = occurrence.updateMask(water)\n",
    "    occurrence_no_data = occurrence.updateMask(no_data)\n",
    "    occurrence_HistogramCount = occurrence_water.reduceRegion(**{\n",
    "        'reducer': ee.Reducer.histogram(100,1),\n",
    "        'geometry': roi,\n",
    "        'scale': 30,\n",
    "        'bestEffort': True,\n",
    "        'tileScale': 2,\n",
    "    })\n",
    "    return class_image.set({'occurrence_HistogramCount': occurrence_HistogramCount.get('occurrence')})\n",
    "\n",
    "def AutomaticCorrection_threshold(class_image):\n",
    "    histogram = ee.List(ee.Dictionary(class_image.get('occurrence_HistogramCount')).get('histogram'))\n",
    "    bucketMeans = ee.List(ee.Dictionary(class_image.get('occurrence_HistogramCount')).get('bucketMeans'))\n",
    "    count_threshold = ee.Number(histogram.reduce(ee.Reducer.sum())).multiply(0.0017)\n",
    "    index = histogram.map(lambda i : ee.Algorithms.If(ee.Number(i).gte(ee.Number(count_threshold)),ee.Number(i))).removeAll([None]).get(0)\n",
    "    occurrence_threshold = bucketMeans.get(histogram.indexOf(index))\n",
    "    return class_image.set({'occurrence_threshold':occurrence_threshold})\n",
    "\n",
    "def AutomaticCorrection_enhanced(class_image):\n",
    "    basemap = ee.Image.constant(0).toFloat().updateMask(class_image.gte(0)).rename('waterclass')\n",
    "    water = class_image.eq(2).selfMask()\n",
    "    occurrence = ee.Image('JRC/GSW1_3/GlobalSurfaceWater').select('occurrence')\n",
    "    occurrence_no_data = occurrence.updateMask(class_image.eq(0).selfMask())\n",
    "    occurrence_threshold = class_image.get('occurrence_threshold')\n",
    "    occurrence_corrected_water = occurrence_no_data.gte(ee.Number(occurrence_threshold)).selfMask().select('occurrence').rename('waterclass')\n",
    "    enhanced_water = ee.ImageCollection([basemap,water,occurrence_corrected_water]).sum()\n",
    "    return enhanced_water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water occurrence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T11:55:21.306840Z",
     "start_time": "2022-04-02T11:55:21.291880Z"
    }
   },
   "source": [
    "You can view the download progress in \"Google earth engine->Code Editor->Tasks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"filtered_samples\" denotes the training sample set downloaded to GEE's Assets in \"01--Automatic training sample construction.ipynb\",which needs to be adapted to your situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T12:48:32.316317Z",
     "start_time": "2022-03-07T12:47:46.030940Z"
    }
   },
   "outputs": [],
   "source": [
    "# TIME = [['2000'],['2005'],['2010'],['2015'],['2020']]\n",
    "TIME = [['2020']]\n",
    "for time in TIME:\n",
    "    print(time[0])\n",
    "    startDate = time[0] + '-01-01'\n",
    "    endDate = time[0] + '-12-31'\n",
    "    l5 = ee.ImageCollection('LANDSAT/LT05/C01/T1_SR') \\\n",
    "           .select(['B1', 'B2', 'B3', 'B4', 'B5', 'B7','pixel_qa'],['B2', 'B3', 'B4', 'B5', 'B6', 'B7','pixel_qa']) \\\n",
    "           .filterBounds(roi) \\\n",
    "           .filterDate(startDate, endDate)  \n",
    "    l7 = ee.ImageCollection('LANDSAT/LE07/C01/T1_SR') \\\n",
    "           .select(['B1', 'B2', 'B3', 'B4', 'B5', 'B7','pixel_qa'],['B2', 'B3', 'B4', 'B5', 'B6', 'B7','pixel_qa']) \\\n",
    "           .filterBounds(roi) \\\n",
    "           .filterDate(startDate, endDate)           \n",
    "    l8 = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR') \\\n",
    "           .select(['B2', 'B3', 'B4', 'B5', 'B6', 'B7','pixel_qa']) \\\n",
    "           .filterBounds(roi) \\\n",
    "           .filterDate(startDate, endDate)\n",
    "    landsat_image = l8.merge(l7).merge(l5).map(water_index)\n",
    "    \n",
    "    label = 'waterclass'\n",
    "    bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7','NDVI','NDWI','mNDWI','CWI','AWEI','EWI','EVI']\n",
    "    filtered_samples = ee.FeatureCollection('users/311605001111/' + region + '/' + region + '_9920')\n",
    "    trainedClassifier = ee.Classifier.smileRandomForest(150).train(filtered_samples,label,bands)\n",
    "    landsat_images = landsat_image.map(classified_image).filter(ee.Filter.gte('invalid_percentage',5)).filter(ee.Filter.lt('invalid_percentage',95))\n",
    "    No_correct_image5 = landsat_image.map(classified_image).filter(ee.Filter.lt('invalid_percentage',5))\n",
    "    No_correct_image6 = landsat_image.map(classified_image).filter(ee.Filter.gte('invalid_percentage',95))\n",
    "    probable_correct_image = landsat_images.map(waterArea).filter(ee.Filter.gt('waterarea',5))\n",
    "    No_correct_image1 = landsat_images.map(waterArea).filter(ee.Filter.lte('waterarea',5))\n",
    "    occurrence_threshold = probable_correct_image.map(occurrence_Histogram).filter(ee.Filter.neq('occurrence_HistogramCount',None)).map(AutomaticCorrection_threshold)\n",
    "    correct_image = occurrence_threshold.filter(ee.Filter.gt('occurrence_threshold',5)).filter(ee.Filter.lte('occurrence_threshold',75))\n",
    "    No_correct_image2 = occurrence_threshold.filter(ee.Filter.lte('occurrence_threshold',5))\n",
    "    No_correct_image3 = occurrence_threshold.filter(ee.Filter.gt('occurrence_threshold',75))\n",
    "    No_correct_image4 = probable_correct_image.map(occurrence_Histogram).filter(ee.Filter.eq('occurrence_HistogramCount',None))\n",
    "    correct_image = correct_image\n",
    "    # print('Number of images to be corrected : ',correct_image.size().getInfo())\n",
    "    No_correct_image = No_correct_image1.merge(No_correct_image2).merge(No_correct_image3).merge(No_correct_image4).merge(No_correct_image5).merge(No_correct_image6)\n",
    "    # print('Number of images not to be corrected : ',No_correct_image.size().getInfo())\n",
    "    \n",
    "    #### Calculation of water occurrence\n",
    "    if correct_image.size().getInfo() == 0 :\n",
    "        No_Correct_waterPixel = No_correct_image.map(lambda i : i.select('waterclass').eq(2)).sum()\n",
    "        No_Correct_validPixel = No_correct_image.map(lambda i : i.select('waterclass').gt(0)).sum()\n",
    "        waterfrequency = No_Correct_waterPixel.divide(No_Correct_validPixel).rename('frequency')\n",
    "    else:\n",
    "        correct_waterPixel = correct_image.map(AutomaticCorrection_enhanced).sum()\n",
    "        correct_validPixel = correct_image.map(lambda i : i.select('waterclass').gte(0)).sum()\n",
    "        No_Correct_waterPixel = No_correct_image.map(lambda i : i.select('waterclass').eq(2)).sum()\n",
    "        No_Correct_validPixel = No_correct_image.map(lambda i : i.select('waterclass').gt(0)).sum()\n",
    "        waterPixel = ee.ImageCollection([correct_waterPixel,No_Correct_waterPixel]).sum()\n",
    "        validPixel = ee.ImageCollection([correct_validPixel,No_Correct_validPixel]).sum()\n",
    "        waterfrequency = waterPixel.divide(validPixel).rename('frequency')\n",
    "    # Map.addLayer(waterfrequency,{'palette':['white','green'],'min':0,'max':1},\"water frequency\")\n",
    "    \n",
    "    #### The data is stored in GEE's Assets\n",
    "    ## \"dataset_id\" indicates the file name; \"assetID\" indicates the file path in GEE's Assets.\n",
    "    ## They need to be modified to suit your situation\n",
    "    dataset_id = region + '_WF_' + time[0]\n",
    "    assetID = 'users/311605001111/WF/' + dataset_id\n",
    "    task = ee.batch.Export.image.toAsset(**{\n",
    "        'image': waterfrequency,\n",
    "        'description': dataset_id,\n",
    "        'assetId': assetID,\n",
    "        'scale': 30,\n",
    "        'region': roi,\n",
    "        'maxPixels': 1e13,\n",
    "    })\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix--download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, all processing results are saved to GEE's Assets. \n",
    "\n",
    "If required, they can also be downloaded to a local disk or Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Calling the image data stored in GEE's Assets. \n",
    "## \"data_id\" indicates the image id stored in GEE's Assets\n",
    "\n",
    "data_id = 'users/311605001111/WF/wuhan_WF_2020'\n",
    "waterfrequency = ee.Image(data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### The data will be stored in Google Drive\n",
    "## \"dataset_id\" indicates the file name; \"folder\" indicates the file path in Google Drive.\n",
    "## They need to be modified to suit your situation\n",
    "\n",
    "year = 2020\n",
    "region = 'wuhan'\n",
    "dataset_id = region + '_WF_' + str(year)\n",
    "folder = region + '_WF'\n",
    "\n",
    "task = ee.batch.Export.image.toDrive(**{\n",
    "    'image': waterfrequency,\n",
    "    'description': dataset_id,\n",
    "    'folder': folder,\n",
    "    'scale': 30,\n",
    "    'region': roi,\n",
    "    'maxPixels': 1e13,\n",
    "})\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download to local disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Calling the image data stored in GEE's Assets. \n",
    "## \"data_id\" indicates the image id stored in GEE's Assets\n",
    "\n",
    "data_id = 'users/311605001111/WF/wuhan_WF_2020'\n",
    "waterfrequency = ee.Image(data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### The data will be stored in local dish\n",
    "## \"dataset_id\" indicates the file name; \"folder indicates the file path in local dish.\n",
    "## For example, the path for this experiment is \"D:/wuhan_WF/wuhan_WF_2020.tif\"\n",
    "## They need to be modified to suit your situation\n",
    "\n",
    "year = 2020\n",
    "region = 'wuhan'\n",
    "folder = 'D:/' + region + '_WF/'+ region + '_WF_' + str(year) + '.tif'\n",
    "\n",
    "task = geemap.ee_export_image(**{\n",
    "    'ee_object' : waterfrequency,\n",
    "    'filename' : folder, \n",
    "    'scale' : 30, \n",
    "    'region' : roi, \n",
    "    'file_per_band' : False        \n",
    "})\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "263.097px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
